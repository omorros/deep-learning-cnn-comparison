{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElOs-f2CdBPg",
        "outputId": "f9e36626-5b93-4ca3-b59e-d9673da7c0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SNAPSHELF - DATASET PREPARATION\n",
            "============================================================\n",
            "Execution Date:  2026-01-03 15:59:35\n",
            "Python Version:  3.12.12\n",
            "Platform:        Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# SNAPSHELF - FOOD IMAGE CLASSIFICATION MODEL COMPARISON\n",
        "# ================================================================\n",
        "# Project:      SnapShelf - Smart Food Inventory Management\n",
        "# Module:       MOD002691 - Final Project (BSc Software Engineering)\n",
        "# Institution:  Anglia Ruskin University, Cambridge\n",
        "# Author:       Oriol Morros Vilaseca (SID: 2270056)\n",
        "# Supervisor:   Mr Vitaliy Milke\n",
        "# Date:         January 2026\n",
        "# ================================================================\n",
        "#\n",
        "# PURPOSE:\n",
        "# This notebook prepares a unified dataset for comparing three\n",
        "# image classification approaches for food recognition:\n",
        "#   1. Custom CNN (trained from scratch)\n",
        "#   2. EfficientNetB0 (transfer learning)\n",
        "#   3. YOLOv8 (object detection adapted for classification)\n",
        "#\n",
        "# RESEARCH QUESTION:\n",
        "# How do different image classification approaches compare in\n",
        "# accuracy, inference time, and computational efficiency for\n",
        "# household food item recognition?\n",
        "#\n",
        "# DATASET SOURCES:\n",
        "#   - Kaggle: moltean/fruits (Fruits-360)\n",
        "#   - Kaggle: sshikamaru/fruit-recognition\n",
        "#   - Kaggle: utkarshsaxenadn/fruits-classification\n",
        "#\n",
        "# OUTPUT:\n",
        "# A merged dataset with 70/15/15 train/validation/test split\n",
        "# across 14 food categories, ready for model training.\n",
        "#\n",
        "# ================================================================\n",
        "\n",
        "import sys\n",
        "import platform\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SNAPSHELF - DATASET PREPARATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Execution Date:  {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Python Version:  {sys.version.split()[0]}\")\n",
        "print(f\"Platform:        {platform.platform()}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yIL66oodGBE",
        "outputId": "fc97b1fa-e6bd-4c38-9667-be1d400a1d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Random seed set to: 42\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 2: MOUNT GOOGLE DRIVE & IMPORT LIBRARIES\n",
        "# ================================================================\n",
        "# Google Drive is used for:\n",
        "#   - Loading source datasets (input)\n",
        "#   - Saving processed dataset (output)\n",
        "#   - Persistent storage between Colab sessions\n",
        "#\n",
        "# ================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "print(\"Google Drive mounted successfully.\")\n",
        "print(f\"Random seed set to: {SEED}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z8qluiKd6L0",
        "outputId": "62e7cc28-4ad8-4fdc-8d40-b783e31f2a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PROJECT CONFIGURATION\n",
            "============================================================\n",
            "\n",
            "[SOURCE DATASETS]\n",
            "  fruits_360: ✓\n",
            "  fruit_recognition: ✓\n",
            "  fruits_classification: ✓\n",
            "\n",
            "[OUTPUT LOCATION]\n",
            "  /content/drive/MyDrive/snapshelf_dataset\n",
            "\n",
            "[TARGET CLASSES] (14 categories)\n",
            "  • apple\n",
            "  • banana\n",
            "  • orange\n",
            "  • lemon\n",
            "  • strawberry\n",
            "  • grape\n",
            "  • peach\n",
            "  • tomato\n",
            "  • potato\n",
            "  • onion\n",
            "  • carrot\n",
            "  • bell_pepper_red\n",
            "  • bell_pepper_green\n",
            "  • cucumber\n",
            "\n",
            "[DATA SPLIT]\n",
            "  Train:      70%\n",
            "  Validation: 15%\n",
            "  Test:       15%\n",
            "\n",
            "Configuration validated successfully.\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 3: PROJECT CONFIGURATION\n",
        "# ================================================================\n",
        "# Central configuration for all paths and parameters.\n",
        "# Modify SOURCE_DATASETS if your zip files are in a different location.\n",
        "# ================================================================\n",
        "\n",
        "# -----------------------------\n",
        "# SOURCE DATASET PATHS (Input)\n",
        "# -----------------------------\n",
        "# These are the 3 Kaggle datasets stored in your Google Drive\n",
        "DRIVE_BASE = \"/content/drive/MyDrive/smartfoodai_datasets\"\n",
        "\n",
        "SOURCE_DATASETS = {\n",
        "    \"fruits_360\": f\"{DRIVE_BASE}/archive (3).zip\",        # moltean/fruits\n",
        "    \"fruit_recognition\": f\"{DRIVE_BASE}/archive (1).zip\", # sshikamaru/fruit-recognition\n",
        "    \"fruits_classification\": f\"{DRIVE_BASE}/archive (2).zip\"  # utkarshsaxenadn/fruits-classification\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# OUTPUT PATHS\n",
        "# -----------------------------\n",
        "# Where the processed dataset will be saved\n",
        "OUTPUT_BASE = \"/content/drive/MyDrive/snapshelf_dataset\"\n",
        "EXTRACTION_DIR = \"/content/datasets_raw\"      # Temporary extraction (local)\n",
        "MERGED_DIR = \"/content/merged_dataset\"        # Temporary merged (local)\n",
        "\n",
        "# Final output directories (saved to Drive)\n",
        "TRAIN_DIR = f\"{OUTPUT_BASE}/train\"\n",
        "VAL_DIR = f\"{OUTPUT_BASE}/val\"\n",
        "TEST_DIR = f\"{OUTPUT_BASE}/test\"\n",
        "\n",
        "# -----------------------------\n",
        "# DATASET CONFIGURATION\n",
        "# -----------------------------\n",
        "# 14 target food categories for classification\n",
        "TARGET_CLASSES = {\n",
        "    \"apple\": [\"apple\"],\n",
        "    \"banana\": [\"banana\"],\n",
        "    \"orange\": [\"orange\"],\n",
        "    \"lemon\": [\"lemon\"],\n",
        "    \"strawberry\": [\"strawberry\"],\n",
        "    \"grape\": [\"grape\"],\n",
        "    \"peach\": [\"peach\"],\n",
        "    \"tomato\": [\"tomato\"],\n",
        "    \"potato\": [\"potato\"],\n",
        "    \"onion\": [\"onion\"],\n",
        "    \"carrot\": [\"carrot\"],\n",
        "    \"bell_pepper_red\": [\"pepper red\", \"bell pepper red\", \"red pepper\"],\n",
        "    \"bell_pepper_green\": [\"pepper green\", \"bell pepper green\", \"green pepper\"],\n",
        "    \"cucumber\": [\"cucumber\"]\n",
        "}\n",
        "\n",
        "# Data split ratios (must sum to 1.0)\n",
        "TRAIN_RATIO = 0.70\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "# Image settings\n",
        "VALID_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\"}\n",
        "\n",
        "# -----------------------------\n",
        "# VERIFY CONFIGURATION\n",
        "# -----------------------------\n",
        "print(\"=\" * 60)\n",
        "print(\"PROJECT CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n[SOURCE DATASETS]\")\n",
        "for name, path in SOURCE_DATASETS.items():\n",
        "    exists = \"✓\" if os.path.exists(path) else \"✗ NOT FOUND\"\n",
        "    print(f\"  {name}: {exists}\")\n",
        "\n",
        "print(f\"\\n[OUTPUT LOCATION]\")\n",
        "print(f\"  {OUTPUT_BASE}\")\n",
        "\n",
        "print(f\"\\n[TARGET CLASSES] ({len(TARGET_CLASSES)} categories)\")\n",
        "for cls in TARGET_CLASSES.keys():\n",
        "    print(f\"  • {cls}\")\n",
        "\n",
        "print(f\"\\n[DATA SPLIT]\")\n",
        "print(f\"  Train:      {TRAIN_RATIO*100:.0f}%\")\n",
        "print(f\"  Validation: {VAL_RATIO*100:.0f}%\")\n",
        "print(f\"  Test:       {TEST_RATIO*100:.0f}%\")\n",
        "\n",
        "# Validate split ratios\n",
        "assert abs(TRAIN_RATIO + VAL_RATIO + TEST_RATIO - 1.0) < 0.001, \\\n",
        "    \"ERROR: Split ratios must sum to 1.0\"\n",
        "print(\"\\nConfiguration validated successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkVGD294eRKc",
        "outputId": "a5925e12-9cab-4118-dcf6-f1cb3e4a90e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "EXTRACTING SOURCE DATASETS\n",
            "============================================================\n",
            "\n",
            "Extraction directory: /content/datasets_raw\n",
            "\n",
            "  Extracting fruits_360... ✓\n",
            "  Extracting fruit_recognition... ✓\n",
            "  Extracting fruits_classification... ✓\n",
            "\n",
            "============================================================\n",
            "Extraction complete: 3/3 datasets\n",
            "\n",
            "[EXTRACTED CONTENTS]\n",
            "   Fruits Classification/ (4 items)\n",
            "   fruits-360_100x100/ (1 items)\n",
            "   fruits-360_3-body-problem/ (1 items)\n",
            "   fruits-360_dataset_meta/ (1 items)\n",
            "   fruits-360_multi/ (3 items)\n",
            "   fruits-360_original-size/ (1 items)\n",
            "   sampleSubmission.csv\n",
            "   test/ (1 items)\n",
            "   train/ (1 items)\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 4: EXTRACT SOURCE DATASETS\n",
        "# ================================================================\n",
        "# Extracts all zip files to a temporary local directory.\n",
        "# Local storage is faster than working directly from Drive.\n",
        "# ================================================================\n",
        "\n",
        "import zipfile\n",
        "\n",
        "def extract_dataset(zip_path, extract_to, dataset_name):\n",
        "    \"\"\"\n",
        "    Extract a zip file to the specified directory.\n",
        "\n",
        "    Args:\n",
        "        zip_path: Path to the zip file\n",
        "        extract_to: Destination directory\n",
        "        dataset_name: Name for logging purposes\n",
        "\n",
        "    Returns:\n",
        "        bool: True if successful, False otherwise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"  Extracting {dataset_name}...\", end=\" \")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(\"✓\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error: {e}\")\n",
        "        return False\n",
        "\n",
        "# -----------------------------\n",
        "# EXTRACT ALL DATASETS\n",
        "# -----------------------------\n",
        "print(\"=\" * 60)\n",
        "print(\"EXTRACTING SOURCE DATASETS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create extraction directory (clean start)\n",
        "if os.path.exists(EXTRACTION_DIR):\n",
        "    shutil.rmtree(EXTRACTION_DIR)\n",
        "os.makedirs(EXTRACTION_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\\nExtraction directory: {EXTRACTION_DIR}\\n\")\n",
        "\n",
        "# Extract each dataset\n",
        "success_count = 0\n",
        "for name, zip_path in SOURCE_DATASETS.items():\n",
        "    if extract_dataset(zip_path, EXTRACTION_DIR, name):\n",
        "        success_count += 1\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"Extraction complete: {success_count}/{len(SOURCE_DATASETS)} datasets\")\n",
        "\n",
        "# -----------------------------\n",
        "# SHOW EXTRACTED STRUCTURE\n",
        "# -----------------------------\n",
        "print(f\"\\n[EXTRACTED CONTENTS]\")\n",
        "for item in sorted(os.listdir(EXTRACTION_DIR)):\n",
        "    item_path = os.path.join(EXTRACTION_DIR, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        subcount = len(os.listdir(item_path))\n",
        "        print(f\"   {item}/ ({subcount} items)\")\n",
        "    else:\n",
        "        print(f\"   {item}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGB68kR-e068",
        "outputId": "ec1d640b-405c-402c-d174-d54b0d766449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SCANNING FOR TARGET CLASS IMAGES\n",
            "============================================================\n",
            "\n",
            "Scanning: /content/datasets_raw\n",
            "Looking for 14 target classes...\n",
            "\n",
            "Class                Images Found\n",
            "----------------------------------\n",
            "apple                      69,389\n",
            "banana                      5,699\n",
            "bell_pepper_green           1,036\n",
            "bell_pepper_red             1,554\n",
            "carrot                        402\n",
            "cucumber                   15,773\n",
            "grape                       8,861\n",
            "lemon                       1,804\n",
            "onion                       7,000\n",
            "orange                      3,260\n",
            "peach                      10,996\n",
            "potato                      2,854\n",
            "strawberry                  4,132\n",
            "tomato                     34,606\n",
            "----------------------------------\n",
            "TOTAL                     167,366\n",
            "\n",
            "[SUMMARY]\n",
            "  Classes with images: 14/14\n",
            "  Total images found:  167,366\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 5: SCAN & MAP SOURCE IMAGES TO TARGET CLASSES\n",
        "# ================================================================\n",
        "# Walks through all extracted directories and identifies images\n",
        "# that match our 14 target food categories.\n",
        "# Creates a mapping of source paths to target class names.\n",
        "# ================================================================\n",
        "\n",
        "def matches_target_class(folder_name, keywords):\n",
        "    \"\"\"\n",
        "    Check if a folder name matches any of the target class keywords.\n",
        "\n",
        "    Args:\n",
        "        folder_name: Name of the folder to check\n",
        "        keywords: List of keywords that indicate this class\n",
        "\n",
        "    Returns:\n",
        "        bool: True if folder matches the class\n",
        "    \"\"\"\n",
        "    name_normalized = folder_name.lower().replace(\"_\", \" \").replace(\"-\", \" \")\n",
        "    for keyword in keywords:\n",
        "        if keyword in name_normalized:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def scan_for_images(base_path, target_classes, valid_extensions):\n",
        "    \"\"\"\n",
        "    Recursively scan directories and map images to target classes.\n",
        "\n",
        "    Args:\n",
        "        base_path: Root directory to scan\n",
        "        target_classes: Dict mapping class names to keyword lists\n",
        "        valid_extensions: Set of valid image file extensions\n",
        "\n",
        "    Returns:\n",
        "        Dict mapping class names to lists of image paths\n",
        "    \"\"\"\n",
        "    class_images = defaultdict(list)\n",
        "\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        folder_name = os.path.basename(root)\n",
        "\n",
        "        # Check if this folder matches any target class\n",
        "        for class_name, keywords in target_classes.items():\n",
        "            if matches_target_class(folder_name, keywords):\n",
        "                # Collect all valid images from this folder\n",
        "                for filename in files:\n",
        "                    ext = os.path.splitext(filename)[1].lower()\n",
        "                    if ext in valid_extensions:\n",
        "                        full_path = os.path.join(root, filename)\n",
        "                        class_images[class_name].append(full_path)\n",
        "                break  # Folder matched, no need to check other classes\n",
        "\n",
        "    return class_images\n",
        "\n",
        "# -----------------------------\n",
        "# SCAN ALL EXTRACTED DATASETS\n",
        "# -----------------------------\n",
        "print(\"=\" * 60)\n",
        "print(\"SCANNING FOR TARGET CLASS IMAGES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nScanning: {EXTRACTION_DIR}\")\n",
        "print(f\"Looking for {len(TARGET_CLASSES)} target classes...\")\n",
        "print()\n",
        "\n",
        "class_images = scan_for_images(EXTRACTION_DIR, TARGET_CLASSES, VALID_EXTENSIONS)\n",
        "\n",
        "# -----------------------------\n",
        "# REPORT FINDINGS\n",
        "# -----------------------------\n",
        "print(f\"{'Class':<20} {'Images Found':>12}\")\n",
        "print(\"-\" * 34)\n",
        "\n",
        "total_images = 0\n",
        "classes_found = 0\n",
        "\n",
        "for class_name in sorted(TARGET_CLASSES.keys()):\n",
        "    count = len(class_images[class_name])\n",
        "    total_images += count\n",
        "    if count > 0:\n",
        "        classes_found += 1\n",
        "    status = \"\" if count > 0 else \" [!] NO IMAGES\"\n",
        "    print(f\"{class_name:<20} {count:>12,}{status}\")\n",
        "\n",
        "print(\"-\" * 34)\n",
        "print(f\"{'TOTAL':<20} {total_images:>12,}\")\n",
        "\n",
        "print(f\"\\n[SUMMARY]\")\n",
        "print(f\"  Classes with images: {classes_found}/{len(TARGET_CLASSES)}\")\n",
        "print(f\"  Total images found:  {total_images:,}\")\n",
        "\n",
        "# Warn if any class has no images\n",
        "missing_classes = [c for c in TARGET_CLASSES if len(class_images[c]) == 0]\n",
        "if missing_classes:\n",
        "    print(f\"\\n[WARNING] No images found for: {', '.join(missing_classes)}\")\n",
        "    print(\"  Check TARGET_CLASSES keywords or dataset contents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAiuLYVAfwlp",
        "outputId": "6c4be230-5a67-48d9-9473-124fbc4421cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CREATING TRAIN/VAL/TEST SPLIT\n",
            "============================================================\n",
            "\n",
            "Split ratios: 70% / 15% / 15%\n",
            "Random seed:  42\n",
            "\n",
            "Class                   Train      Val     Test    Total\n",
            "--------------------------------------------------------\n",
            "apple                  48,572   10,408   10,409   69,389\n",
            "banana                  3,989      854      856    5,699\n",
            "bell_pepper_green         725      155      156    1,036\n",
            "bell_pepper_red         1,087      233      234    1,554\n",
            "carrot                    281       60       61      402\n",
            "cucumber               11,041    2,365    2,367   15,773\n",
            "grape                   6,202    1,329    1,330    8,861\n",
            "lemon                   1,262      270      272    1,804\n",
            "onion                   4,900    1,050    1,050    7,000\n",
            "orange                  2,282      489      489    3,260\n",
            "peach                   7,697    1,649    1,650   10,996\n",
            "potato                  1,997      428      429    2,854\n",
            "strawberry              2,892      619      621    4,132\n",
            "tomato                 24,224    5,190    5,192   34,606\n",
            "--------------------------------------------------------\n",
            "TOTAL                 117,151   25,099   25,116  167,366\n",
            "\n",
            "[ACTUAL PERCENTAGES]\n",
            "  Train:      70.0%\n",
            "  Validation: 15.0%\n",
            "  Test:       15.0%\n",
            "\n",
            "Stratified split created successfully.\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 6: CREATE STRATIFIED TRAIN/VAL/TEST SPLIT\n",
        "# ================================================================\n",
        "# Splits images into 70% train, 15% validation, 15% test.\n",
        "# Uses stratified sampling to maintain class proportions.\n",
        "# Shuffles with fixed seed for reproducibility.\n",
        "# ================================================================\n",
        "\n",
        "def create_stratified_split(class_images, train_ratio, val_ratio, test_ratio, seed=42):\n",
        "    \"\"\"\n",
        "    Create stratified train/val/test split for each class.\n",
        "\n",
        "    Args:\n",
        "        class_images: Dict mapping class names to image path lists\n",
        "        train_ratio: Proportion for training set\n",
        "        val_ratio: Proportion for validation set\n",
        "        test_ratio: Proportion for test set\n",
        "        seed: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (train_dict, val_dict, test_dict)\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "\n",
        "    train_split = defaultdict(list)\n",
        "    val_split = defaultdict(list)\n",
        "    test_split = defaultdict(list)\n",
        "\n",
        "    for class_name, image_paths in class_images.items():\n",
        "        # Shuffle images\n",
        "        shuffled = image_paths.copy()\n",
        "        random.shuffle(shuffled)\n",
        "\n",
        "        # Calculate split indices\n",
        "        n = len(shuffled)\n",
        "        train_end = int(n * train_ratio)\n",
        "        val_end = train_end + int(n * val_ratio)\n",
        "\n",
        "        # Split\n",
        "        train_split[class_name] = shuffled[:train_end]\n",
        "        val_split[class_name] = shuffled[train_end:val_end]\n",
        "        test_split[class_name] = shuffled[val_end:]\n",
        "\n",
        "    return train_split, val_split, test_split\n",
        "\n",
        "# -----------------------------\n",
        "# PERFORM SPLIT\n",
        "# -----------------------------\n",
        "print(\"=\" * 60)\n",
        "print(\"CREATING TRAIN/VAL/TEST SPLIT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nSplit ratios: {TRAIN_RATIO*100:.0f}% / {VAL_RATIO*100:.0f}% / {TEST_RATIO*100:.0f}%\")\n",
        "print(f\"Random seed:  {SEED}\")\n",
        "print()\n",
        "\n",
        "train_split, val_split, test_split = create_stratified_split(\n",
        "    class_images,\n",
        "    TRAIN_RATIO,\n",
        "    VAL_RATIO,\n",
        "    TEST_RATIO,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# REPORT SPLIT DISTRIBUTION\n",
        "# -----------------------------\n",
        "print(f\"{'Class':<20} {'Train':>8} {'Val':>8} {'Test':>8} {'Total':>8}\")\n",
        "print(\"-\" * 56)\n",
        "\n",
        "total_train = total_val = total_test = 0\n",
        "\n",
        "for class_name in sorted(TARGET_CLASSES.keys()):\n",
        "    n_train = len(train_split[class_name])\n",
        "    n_val = len(val_split[class_name])\n",
        "    n_test = len(test_split[class_name])\n",
        "    n_total = n_train + n_val + n_test\n",
        "\n",
        "    total_train += n_train\n",
        "    total_val += n_val\n",
        "    total_test += n_test\n",
        "\n",
        "    print(f\"{class_name:<20} {n_train:>8,} {n_val:>8,} {n_test:>8,} {n_total:>8,}\")\n",
        "\n",
        "print(\"-\" * 56)\n",
        "total_all = total_train + total_val + total_test\n",
        "print(f\"{'TOTAL':<20} {total_train:>8,} {total_val:>8,} {total_test:>8,} {total_all:>8,}\")\n",
        "\n",
        "# Verify percentages\n",
        "print(f\"\\n[ACTUAL PERCENTAGES]\")\n",
        "print(f\"  Train:      {total_train/total_all*100:.1f}%\")\n",
        "print(f\"  Validation: {total_val/total_all*100:.1f}%\")\n",
        "print(f\"  Test:       {total_test/total_all*100:.1f}%\")\n",
        "\n",
        "print(f\"\\nStratified split created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xrXoX3IghSV",
        "outputId": "ac58f06a-e0a6-4d68-84dd-9c9da637f598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "COPYING IMAGES TO LOCAL DIRECTORY\n",
            "============================================================\n",
            "\n",
            "Destination: /content/snapshelf_dataset (local Colab storage)\n",
            "\n",
            "Copying images...\n",
            "\n",
            "  [TRAIN] Copying... 117,151 images done.\n",
            "  [VAL] Copying... 25,099 images done.\n",
            "  [TEST] Copying... 25,116 images done.\n",
            "\n",
            "============================================================\n",
            "COPY COMPLETE\n",
            "============================================================\n",
            "\n",
            "Split              Images\n",
            "--------------------------\n",
            "train             117,151\n",
            "val                25,099\n",
            "test               25,116\n",
            "--------------------------\n",
            "TOTAL             167,366\n",
            "\n",
            "Dataset ready at: /content/snapshelf_dataset\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 7: COPY IMAGES TO LOCAL DIRECTORY STRUCTURE\n",
        "# ================================================================\n",
        "# Copies images to LOCAL Colab storage (fast), not Drive (slow).\n",
        "# Final step will zip and upload to Drive.\n",
        "#\n",
        "# Directory structure:\n",
        "#   /content/snapshelf_dataset/\n",
        "#       train/class_name/\n",
        "#       val/class_name/\n",
        "#       test/class_name/\n",
        "# ================================================================\n",
        "\n",
        "def copy_split_to_directory(split_dict, output_dir, split_name):\n",
        "    \"\"\"\n",
        "    Copy images from split dictionary to output directory.\n",
        "\n",
        "    Args:\n",
        "        split_dict: Dict mapping class names to image path lists\n",
        "        output_dir: Destination directory\n",
        "        split_name: Name of split for logging (train/val/test)\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of images copied\n",
        "    \"\"\"\n",
        "    total_copied = 0\n",
        "\n",
        "    for class_name, image_paths in split_dict.items():\n",
        "        # Create class subdirectory\n",
        "        class_dir = os.path.join(output_dir, class_name)\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        # Copy images with unique names to avoid overwrites\n",
        "        for idx, src_path in enumerate(image_paths):\n",
        "            ext = os.path.splitext(src_path)[1].lower()\n",
        "            dst_filename = f\"{class_name}_{idx:05d}{ext}\"\n",
        "            dst_path = os.path.join(class_dir, dst_filename)\n",
        "\n",
        "            try:\n",
        "                shutil.copy2(src_path, dst_path)\n",
        "                total_copied += 1\n",
        "            except Exception as e:\n",
        "                print(f\"  [ERROR] Failed to copy {src_path}: {e}\")\n",
        "\n",
        "    return total_copied\n",
        "\n",
        "# -----------------------------\n",
        "# USE LOCAL STORAGE (FAST)\n",
        "# -----------------------------\n",
        "LOCAL_OUTPUT = \"/content/snapshelf_dataset\"\n",
        "LOCAL_TRAIN = f\"{LOCAL_OUTPUT}/train\"\n",
        "LOCAL_VAL = f\"{LOCAL_OUTPUT}/val\"\n",
        "LOCAL_TEST = f\"{LOCAL_OUTPUT}/test\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"COPYING IMAGES TO LOCAL DIRECTORY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nDestination: {LOCAL_OUTPUT} (local Colab storage)\")\n",
        "\n",
        "# Remove existing output directory if it exists\n",
        "if os.path.exists(LOCAL_OUTPUT):\n",
        "    shutil.rmtree(LOCAL_OUTPUT)\n",
        "\n",
        "os.makedirs(LOCAL_OUTPUT, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# COPY EACH SPLIT\n",
        "# -----------------------------\n",
        "splits = [\n",
        "    (\"train\", train_split, LOCAL_TRAIN),\n",
        "    (\"val\", val_split, LOCAL_VAL),\n",
        "    (\"test\", test_split, LOCAL_TEST)\n",
        "]\n",
        "\n",
        "print(f\"\\nCopying images...\\n\")\n",
        "\n",
        "copy_results = {}\n",
        "\n",
        "for split_name, split_data, split_dir in splits:\n",
        "    print(f\"  [{split_name.upper()}] Copying...\", end=\" \", flush=True)\n",
        "    count = copy_split_to_directory(split_data, split_dir, split_name)\n",
        "    copy_results[split_name] = count\n",
        "    print(f\"{count:,} images done.\")\n",
        "\n",
        "# -----------------------------\n",
        "# VERIFY RESULTS\n",
        "# -----------------------------\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"COPY COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n{'Split':<12} {'Images':>12}\")\n",
        "print(\"-\" * 26)\n",
        "for split_name, count in copy_results.items():\n",
        "    print(f\"{split_name:<12} {count:>12,}\")\n",
        "print(\"-\" * 26)\n",
        "print(f\"{'TOTAL':<12} {sum(copy_results.values()):>12,}\")\n",
        "\n",
        "print(f\"\\nDataset ready at: {LOCAL_OUTPUT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiELFHoKrpbJ",
        "outputId": "7e070f76-0950-4cda-d4a6-5788db05fc26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CREATING ZIP ARCHIVE\n",
            "============================================================\n",
            "\n",
            "Source:      /content/snapshelf_dataset\n",
            "Destination: /content/snapshelf_dataset_14classes_70-15-15.zip\n",
            "\n",
            "Compressing (this may take a few minutes)...\n",
            "  Compressed 25,000 files...\n",
            "  Compressed 50,000 files...\n",
            "  Compressed 75,000 files...\n",
            "  Compressed 100,000 files...\n",
            "  Compressed 125,000 files...\n",
            "  Compressed 150,000 files...\n",
            "\n",
            "  Compression complete.\n",
            "  Files:    167,366\n",
            "  Size:     2445.3 MB\n",
            "  Time:     167 seconds\n",
            "\n",
            "============================================================\n",
            "SAVING TO GOOGLE DRIVE\n",
            "============================================================\n",
            "\n",
            "Copying to: /content/drive/MyDrive/snapshelf_datasets/snapshelf_dataset_14classes_70-15-15.zip\n",
            "Please wait...\n",
            "\n",
            "[OK] Successfully saved to Google Drive\n",
            "     File: snapshelf_dataset_14classes_70-15-15.zip\n",
            "     Size: 2445.3 MB\n",
            "\n",
            "============================================================\n",
            "DATASET PREPARATION COMPLETE\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 8: CREATE ZIP ARCHIVE & SAVE TO GOOGLE DRIVE\n",
        "# ================================================================\n",
        "# Compresses the dataset into a single zip file for:\n",
        "#   - Fast transfer to Google Drive\n",
        "#   - Easy download/backup\n",
        "#   - Quick loading in future notebooks\n",
        "# ================================================================\n",
        "\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------------\n",
        "ZIP_FILENAME = \"snapshelf_dataset_14classes_70-15-15.zip\"\n",
        "LOCAL_ZIP_PATH = f\"/content/{ZIP_FILENAME}\"\n",
        "DRIVE_ZIP_PATH = f\"/content/drive/MyDrive/snapshelf_datasets/{ZIP_FILENAME}\"\n",
        "\n",
        "# Ensure Drive destination folder exists\n",
        "os.makedirs(os.path.dirname(DRIVE_ZIP_PATH), exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# CREATE ZIP ARCHIVE\n",
        "# -----------------------------\n",
        "print(\"=\" * 60)\n",
        "print(\"CREATING ZIP ARCHIVE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nSource:      {LOCAL_OUTPUT}\")\n",
        "print(f\"Destination: {LOCAL_ZIP_PATH}\")\n",
        "print(f\"\\nCompressing (this may take a few minutes)...\")\n",
        "\n",
        "start_time = datetime.now()\n",
        "file_count = 0\n",
        "\n",
        "with zipfile.ZipFile(LOCAL_ZIP_PATH, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(LOCAL_OUTPUT):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(file_path, LOCAL_OUTPUT)\n",
        "            zipf.write(file_path, arcname)\n",
        "            file_count += 1\n",
        "\n",
        "            # Progress indicator every 25000 files\n",
        "            if file_count % 25000 == 0:\n",
        "                print(f\"  Compressed {file_count:,} files...\")\n",
        "\n",
        "elapsed = (datetime.now() - start_time).seconds\n",
        "zip_size_mb = os.path.getsize(LOCAL_ZIP_PATH) / (1024 * 1024)\n",
        "\n",
        "print(f\"\\n  Compression complete.\")\n",
        "print(f\"  Files:    {file_count:,}\")\n",
        "print(f\"  Size:     {zip_size_mb:.1f} MB\")\n",
        "print(f\"  Time:     {elapsed} seconds\")\n",
        "\n",
        "# -----------------------------\n",
        "# COPY TO GOOGLE DRIVE\n",
        "# -----------------------------\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"SAVING TO GOOGLE DRIVE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nCopying to: {DRIVE_ZIP_PATH}\")\n",
        "print(\"Please wait...\")\n",
        "\n",
        "shutil.copy2(LOCAL_ZIP_PATH, DRIVE_ZIP_PATH)\n",
        "\n",
        "# Verify\n",
        "if os.path.exists(DRIVE_ZIP_PATH):\n",
        "    drive_size_mb = os.path.getsize(DRIVE_ZIP_PATH) / (1024 * 1024)\n",
        "    print(f\"\\n[OK] Successfully saved to Google Drive\")\n",
        "    print(f\"     File: {ZIP_FILENAME}\")\n",
        "    print(f\"     Size: {drive_size_mb:.1f} MB\")\n",
        "else:\n",
        "    print(f\"\\n[ERROR] Failed to save to Google Drive\")\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"DATASET PREPARATION COMPLETE\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzoYMKmxstuG",
        "outputId": "68fd4f1c-ea69-4e90-d696-90730f444988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "SNAPSHELF DATASET - SUMMARY REPORT\n",
            "======================================================================\n",
            "\n",
            "DATASET INFORMATION\n",
            "-------------------\n",
            "Created:        2026-01-03 16:38:04\n",
            "Source:         3 Kaggle datasets (Fruits-360, Fruit Recognition, \n",
            "                Fruits Classification)\n",
            "Classes:        14\n",
            "Total Images:   167,366\n",
            "Split Ratio:    70% / 15% / 15% (Train / Validation / Test)\n",
            "Random Seed:    42\n",
            "\n",
            "FILE LOCATION\n",
            "-------------\n",
            "Google Drive:   /content/drive/MyDrive/snapshelf_datasets/snapshelf_dataset_14classes_70-15-15.zip\n",
            "Archive Size:   2445.3 MB\n",
            "\n",
            "SPLIT DISTRIBUTION\n",
            "------------------\n",
            "Training Set:   117,151 images (70.0%)\n",
            "Validation Set: 25,099 images (15.0%)\n",
            "Test Set:       25,116 images (15.0%)\n",
            "\n",
            "CLASS DISTRIBUTION\n",
            "----------------------------------------------------------------------\n",
            "Class                     Train        Val       Test      Total\n",
            "----------------------------------------------------------------------\n",
            "apple                    48,572     10,408     10,409     69,389\n",
            "banana                    3,989        854        856      5,699\n",
            "bell_pepper_green           725        155        156      1,036\n",
            "bell_pepper_red           1,087        233        234      1,554\n",
            "carrot                      281         60         61        402\n",
            "cucumber                 11,041      2,365      2,367     15,773\n",
            "grape                     6,202      1,329      1,330      8,861\n",
            "lemon                     1,262        270        272      1,804\n",
            "onion                     4,900      1,050      1,050      7,000\n",
            "orange                    2,282        489        489      3,260\n",
            "peach                     7,697      1,649      1,650     10,996\n",
            "potato                    1,997        428        429      2,854\n",
            "strawberry                2,892        619        621      4,132\n",
            "tomato                   24,224      5,190      5,192     34,606\n",
            "----------------------------------------------------------------------\n",
            "TOTAL                   117,151     25,099     25,116    167,366\n",
            "\n",
            "CLASS IMBALANCE NOTE\n",
            "--------------------\n",
            "Largest class:  apple (69,389 images)\n",
            "Smallest class: carrot (402 images)\n",
            "Imbalance ratio: 172.6:1\n",
            "\n",
            "This imbalance should be noted in the dissertation methodology section.\n",
            "Consider using class weights or stratified sampling during training.\n",
            "\n",
            "======================================================================\n",
            "END OF REPORT\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 9: GENERATE DATASET SUMMARY REPORT\n",
        "# ================================================================\n",
        "# Creates a summary of the dataset for documentation purposes.\n",
        "# This information will be useful for your dissertation.\n",
        "# ================================================================\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "# -----------------------------\n",
        "# CALCULATE STATISTICS\n",
        "# -----------------------------\n",
        "class_stats = []\n",
        "for class_name in sorted(TARGET_CLASSES.keys()):\n",
        "    n_train = len(train_split[class_name])\n",
        "    n_val = len(val_split[class_name])\n",
        "    n_test = len(test_split[class_name])\n",
        "    n_total = n_train + n_val + n_test\n",
        "    class_stats.append({\n",
        "        \"class\": class_name,\n",
        "        \"train\": n_train,\n",
        "        \"val\": n_val,\n",
        "        \"test\": n_test,\n",
        "        \"total\": n_total\n",
        "    })\n",
        "\n",
        "total_train = sum(c[\"train\"] for c in class_stats)\n",
        "total_val = sum(c[\"val\"] for c in class_stats)\n",
        "total_test = sum(c[\"test\"] for c in class_stats)\n",
        "total_all = total_train + total_val + total_test\n",
        "\n",
        "# -----------------------------\n",
        "# PRINT REPORT\n",
        "# -----------------------------\n",
        "print(\"=\" * 70)\n",
        "print(\"SNAPSHELF DATASET - SUMMARY REPORT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\"\"\n",
        "DATASET INFORMATION\n",
        "-------------------\n",
        "Created:        {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "Source:         3 Kaggle datasets (Fruits-360, Fruit Recognition,\n",
        "                Fruits Classification)\n",
        "Classes:        {len(TARGET_CLASSES)}\n",
        "Total Images:   {total_all:,}\n",
        "Split Ratio:    70% / 15% / 15% (Train / Validation / Test)\n",
        "Random Seed:    {SEED}\n",
        "\n",
        "FILE LOCATION\n",
        "-------------\n",
        "Google Drive:   {DRIVE_ZIP_PATH}\n",
        "Archive Size:   {zip_size_mb:.1f} MB\n",
        "\n",
        "SPLIT DISTRIBUTION\n",
        "------------------\n",
        "Training Set:   {total_train:,} images ({total_train/total_all*100:.1f}%)\n",
        "Validation Set: {total_val:,} images ({total_val/total_all*100:.1f}%)\n",
        "Test Set:       {total_test:,} images ({total_test/total_all*100:.1f}%)\n",
        "\"\"\")\n",
        "\n",
        "print(\"CLASS DISTRIBUTION\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Class':<20} {'Train':>10} {'Val':>10} {'Test':>10} {'Total':>10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for stat in class_stats:\n",
        "    print(f\"{stat['class']:<20} {stat['train']:>10,} {stat['val']:>10,} {stat['test']:>10,} {stat['total']:>10,}\")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'TOTAL':<20} {total_train:>10,} {total_val:>10,} {total_test:>10,} {total_all:>10,}\")\n",
        "\n",
        "# -----------------------------\n",
        "# CLASS IMBALANCE NOTE\n",
        "# -----------------------------\n",
        "max_class = max(class_stats, key=lambda x: x[\"total\"])\n",
        "min_class = min(class_stats, key=lambda x: x[\"total\"])\n",
        "imbalance_ratio = max_class[\"total\"] / min_class[\"total\"]\n",
        "\n",
        "print(f\"\"\"\n",
        "CLASS IMBALANCE NOTE\n",
        "--------------------\n",
        "Largest class:  {max_class['class']} ({max_class['total']:,} images)\n",
        "Smallest class: {min_class['class']} ({min_class['total']:,} images)\n",
        "Imbalance ratio: {imbalance_ratio:.1f}:1\n",
        "\n",
        "This imbalance should be noted in the dissertation methodology section.\n",
        "Consider using class weights or stratified sampling during training.\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"END OF REPORT\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBIl--_wwCBe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOAK6dBW1UHxBVvdooOmPMh",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
