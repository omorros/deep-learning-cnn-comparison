{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "08OHhIsGWGip"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MOD002691 - FINAL PROJECT: MODEL COMPARISON ANALYSIS\n",
    "# ============================================================================\n",
    "#\n",
    "# Author:       Oriol Morros Vilaseca (SID: 2270056)\n",
    "# Supervisor:   Mr Vitaliy Milke\n",
    "# Institution:  Anglia Ruskin University, Cambridge\n",
    "# Module:       MOD002691 - Final Project (BSc Software Engineering)\n",
    "# Date:         January 2026\n",
    "#\n",
    "# ============================================================================\n",
    "# PURPOSE\n",
    "# ============================================================================\n",
    "#\n",
    "# Comprehensive comparison of three trained models for food classification:\n",
    "#   1. Custom CNN (baseline, trained from scratch)\n",
    "#   2. EfficientNetB0 (transfer learning)\n",
    "#   3. ResNet-50 (transfer learning)\n",
    "#\n",
    "# This notebook loads pre-computed results from individual training runs\n",
    "# and generates comparative visualisations and statistical analysis.\n",
    "#\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzYy-ASiWGir",
    "outputId": "c49347fd-2889-4737-ce68-214bcbe54aaa"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "MODEL COMPARISON ANALYSIS\n",
      "======================================================================\n",
      "Execution:  2026-02-11 16:56:17\n",
      "Python:     3.12.12\n",
      "Platform:   Linux-6.6.105+-x86_64-with-glibc2.35\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: ENVIRONMENT SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL COMPARISON ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Execution:  {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Python:     {sys.version.split()[0]}\")\n",
    "print(f\"Platform:   {platform.platform()}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "COLORS = {'Custom CNN': '#2ecc71', 'EfficientNetB0': '#3498db', 'ResNet-50': '#e74c3c'}\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: TRAINING RESULTS (HARDCODED FROM ORIGINAL TRAINING NOTEBOOKS)\n",
    "# ============================================================================\n",
    "# Results are embedded directly rather than loaded from JSON files to ensure\n",
    "# consistency. Values were extracted from the cell outputs of notebooks:\n",
    "#   - 03_custom_cnn_training.ipynb\n",
    "#   - 04_efficientnet_training.ipynb\n",
    "#   - 05_resnet50_training.ipynb\n",
    "#\n",
    "# The Drive JSON files were inadvertently overwritten during a second run,\n",
    "# corrupting the original values. Hardcoding from notebook outputs guarantees\n",
    "# the comparison uses the correct, original training results.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# CUSTOM CNN (03_custom_cnn_training.ipynb)\n",
    "# ============================================================================\n",
    "\n",
    "custom_cnn = {\n",
    "    \"model_name\": \"Custom CNN\",\n",
    "    \"architecture\": {\n",
    "        \"type\": \"Custom CNN (from scratch)\",\n",
    "        \"conv_blocks\": 4,\n",
    "        \"filters_per_block\": [64, 128, 256, 512],\n",
    "        \"convs_per_block\": 2,\n",
    "        \"pooling\": \"GlobalAveragePooling2D\",\n",
    "        \"dense_units\": 512,\n",
    "        \"dropout\": 0.5,\n",
    "        \"activation\": \"relu\",\n",
    "        \"input_size\": [224, 224],\n",
    "        \"num_classes\": 14\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"total_epochs\": 81,\n",
    "        \"best_epoch\": 60,\n",
    "        \"training_time_seconds\": 89129,  # See correction note below\n",
    "        \"batch_size\": 32,\n",
    "        \"image_size\": [224, 224],\n",
    "        \"used_class_weights\": True,\n",
    "        \"pretrained\": False,\n",
    "        \"augmentation\": {\n",
    "            \"rotation_range\": 20, \"width_shift_range\": 0.1,\n",
    "            \"height_shift_range\": 0.1, \"shear_range\": 0.1,\n",
    "            \"zoom_range\": 0.1, \"horizontal_flip\": True,\n",
    "            \"fill_mode\": \"nearest\"\n",
    "        }\n",
    "    },\n",
    "    \"performance\": {\n",
    "        \"best_val_accuracy\": 0.9821,\n",
    "        \"test_accuracy\": 0.9834,\n",
    "        \"test_loss\": 0.0485\n",
    "    },\n",
    "    \"per_class_metrics\": {\n",
    "        \"apple\":              {\"precision\": 0.9982, \"recall\": 0.9673, \"f1_score\": 0.9825, \"support\": 6819},\n",
    "        \"banana\":             {\"precision\": 0.8554, \"recall\": 0.9653, \"f1_score\": 0.9070, \"support\": 778},\n",
    "        \"bell_pepper_green\":  {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 90},\n",
    "        \"bell_pepper_red\":    {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 134},\n",
    "        \"carrot\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 61},\n",
    "        \"cucumber\":           {\"precision\": 0.9996, \"recall\": 1.0000, \"f1_score\": 0.9998, \"support\": 2308},\n",
    "        \"grape\":              {\"precision\": 0.9185, \"recall\": 0.9541, \"f1_score\": 0.9359, \"support\": 980},\n",
    "        \"lemon\":              {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 198},\n",
    "        \"onion\":              {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 985},\n",
    "        \"orange\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 97},\n",
    "        \"peach\":              {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 1577},\n",
    "        \"potato\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 362},\n",
    "        \"strawberry\":         {\"precision\": 0.8728, \"recall\": 0.9889, \"f1_score\": 0.9272, \"support\": 541},\n",
    "        \"tomato\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 3211}\n",
    "    },\n",
    "    \"efficiency\": {\n",
    "        \"total_parameters\": 4964942,\n",
    "        \"trainable_parameters\": 4960078,\n",
    "        \"model_size_mb\": 56.92,\n",
    "        \"inference_time_single_ms\": 64.97,\n",
    "        \"inference_time_batch_ms\": 7.09\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING TIME CORRECTION: Custom CNN\n",
    "# ============================================================================\n",
    "# The Custom CNN training was interrupted by a Colab runtime disconnection\n",
    "# at epoch 66. Training resumed from the epoch 65 checkpoint (checkpoints\n",
    "# saved every 5 epochs). The runtime timer only captured the resumed session\n",
    "# (epochs 65-81 = 16 epochs in 17,391s) because the crash prevented the\n",
    "# first session's wall-clock time from being recorded.\n",
    "#\n",
    "# Correction: 17,391s / 16 epochs = 1,086.9s/epoch x 81 epochs = 89,129s\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# EFFICIENTNETB0 (04_efficientnet_training.ipynb)\n",
    "# ============================================================================\n",
    "\n",
    "efficientnet = {\n",
    "    \"model_name\": \"EfficientNetB0\",\n",
    "    \"architecture\": {\n",
    "        \"type\": \"Transfer Learning\",\n",
    "        \"base_model\": \"EfficientNetB0\",\n",
    "        \"pretrained_on\": \"ImageNet\",\n",
    "        \"base_layers\": 238,\n",
    "        \"fine_tuned_layers\": 72,\n",
    "        \"dropout\": 0.3,\n",
    "        \"input_size\": [224, 224],\n",
    "        \"num_classes\": 14\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"phase1_epochs\": 10,\n",
    "        \"total_epochs\": 42,\n",
    "        \"best_epoch\": 40,\n",
    "        \"training_time_seconds\": 39458,\n",
    "        \"batch_size\": 32,\n",
    "        \"image_size\": [224, 224],\n",
    "        \"used_class_weights\": True,\n",
    "        \"augmentation\": {\n",
    "            \"rotation_range\": 20, \"width_shift_range\": 0.1,\n",
    "            \"height_shift_range\": 0.1, \"shear_range\": 0.1,\n",
    "            \"zoom_range\": 0.1, \"horizontal_flip\": True,\n",
    "            \"fill_mode\": \"nearest\"\n",
    "        }\n",
    "    },\n",
    "    \"performance\": {\n",
    "        \"best_val_accuracy\": 0.9972,\n",
    "        \"test_accuracy\": 0.9975,\n",
    "        \"test_loss\": 0.0207\n",
    "    },\n",
    "    \"per_class_metrics\": {\n",
    "        \"apple\":              {\"precision\": 0.9968, \"recall\": 0.9978, \"f1_score\": 0.9973, \"support\": 6819},\n",
    "        \"banana\":             {\"precision\": 0.9871, \"recall\": 0.9859, \"f1_score\": 0.9865, \"support\": 778},\n",
    "        \"bell_pepper_green\":  {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 90},\n",
    "        \"bell_pepper_red\":    {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 134},\n",
    "        \"carrot\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 61},\n",
    "        \"cucumber\":           {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 2308},\n",
    "        \"grape\":              {\"precision\": 0.9878, \"recall\": 0.9898, \"f1_score\": 0.9888, \"support\": 980},\n",
    "        \"lemon\":              {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 198},\n",
    "        \"onion\":              {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 985},\n",
    "        \"orange\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 97},\n",
    "        \"peach\":              {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 1577},\n",
    "        \"potato\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 362},\n",
    "        \"strawberry\":         {\"precision\": 0.9962, \"recall\": 0.9815, \"f1_score\": 0.9888, \"support\": 541},\n",
    "        \"tomato\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 3211}\n",
    "    },\n",
    "    \"efficiency\": {\n",
    "        \"total_parameters\": 4072625,\n",
    "        \"trainable_parameters\": 3099626,\n",
    "        \"model_size_mb\": 40.03,\n",
    "        \"inference_time_single_ms\": 68.70,\n",
    "        \"inference_time_batch_ms\": 14.10\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# RESNET-50 (05_resnet50_training.ipynb)\n",
    "# ============================================================================\n",
    "\n",
    "resnet50 = {\n",
    "    \"model_name\": \"ResNet-50\",\n",
    "    \"architecture\": {\n",
    "        \"type\": \"Transfer Learning\",\n",
    "        \"base_model\": \"ResNet-50\",\n",
    "        \"pretrained_on\": \"ImageNet\",\n",
    "        \"base_layers\": 175,\n",
    "        \"fine_tuned_layers\": 35,\n",
    "        \"dense_units\": 256,\n",
    "        \"dropout\": 0.3,\n",
    "        \"input_size\": [224, 224],\n",
    "        \"num_classes\": 14\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"phase1_epochs\": 10,\n",
    "        \"total_epochs\": 32,\n",
    "        \"best_epoch\": 28,\n",
    "        \"training_time_seconds\": 29273,\n",
    "        \"batch_size\": 32,\n",
    "        \"image_size\": [224, 224],\n",
    "        \"used_class_weights\": True,\n",
    "        \"augmentation\": {\n",
    "            \"rotation_range\": 20, \"width_shift_range\": 0.1,\n",
    "            \"height_shift_range\": 0.1, \"shear_range\": 0.1,\n",
    "            \"zoom_range\": 0.1, \"horizontal_flip\": True,\n",
    "            \"fill_mode\": \"nearest\"\n",
    "        }\n",
    "    },\n",
    "    \"performance\": {\n",
    "        \"best_val_accuracy\": 0.9972,\n",
    "        \"test_accuracy\": 0.9977,\n",
    "        \"test_loss\": 0.0128\n",
    "    },\n",
    "    \"per_class_metrics\": {\n",
    "        \"apple\":              {\"precision\": 0.9975, \"recall\": 0.9978, \"f1_score\": 0.9977, \"support\": 6819},\n",
    "        \"banana\":             {\"precision\": 0.9910, \"recall\": 0.9897, \"f1_score\": 0.9904, \"support\": 778},\n",
    "        \"bell_pepper_green\":  {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 90},\n",
    "        \"bell_pepper_red\":    {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 134},\n",
    "        \"carrot\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 61},\n",
    "        \"cucumber\":           {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 2308},\n",
    "        \"grape\":              {\"precision\": 0.9898, \"recall\": 0.9888, \"f1_score\": 0.9893, \"support\": 980},\n",
    "        \"lemon\":              {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 198},\n",
    "        \"onion\":              {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 985},\n",
    "        \"orange\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 97},\n",
    "        \"peach\":              {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 1577},\n",
    "        \"potato\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 362},\n",
    "        \"strawberry\":         {\"precision\": 0.9852, \"recall\": 0.9852, \"f1_score\": 0.9852, \"support\": 541},\n",
    "        \"tomato\":             {\"precision\": 1.0000, \"recall\": 1.0000, \"f1_score\": 1.0000, \"support\": 3211}\n",
    "    },\n",
    "    \"efficiency\": {\n",
    "        \"total_parameters\": 24125070,\n",
    "        \"trainable_parameters\": 15510798,\n",
    "        \"model_size_mb\": 211.03,\n",
    "        \"inference_time_single_ms\": 68.23,\n",
    "        \"inference_time_batch_ms\": 10.10\n",
    "    }\n",
    "}\n",
    "\n",
    "results = {\n",
    "    'Custom CNN': custom_cnn,\n",
    "    'EfficientNetB0': efficientnet,\n",
    "    'ResNet-50': resnet50\n",
    "}\n",
    "\n",
    "print(\"Results loaded (hardcoded from original training notebook outputs).\")\n",
    "print(f\"  Custom CNN:     {custom_cnn['performance']['test_accuracy']*100:.2f}% accuracy, {custom_cnn['training']['total_epochs']} epochs\")\n",
    "print(f\"  EfficientNetB0: {efficientnet['performance']['test_accuracy']*100:.2f}% accuracy, {efficientnet['training']['total_epochs']} epochs\")\n",
    "print(f\"  ResNet-50:      {resnet50['performance']['test_accuracy']*100:.2f}% accuracy, {resnet50['training']['total_epochs']} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1Y1KJBnWGit",
    "outputId": "9ad99014-c638-451e-de9c-8f0e93c3d948"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: PERFORMANCE SUMMARY TABLE\n",
    "# ============================================================================\n",
    "# Consolidated view of key metrics across all models.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_data = []\n",
    "for name, r in results.items():\n",
    "    hours = r['training']['training_time_seconds'] / 3600\n",
    "    summary_data.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy (%)': round(r['performance']['test_accuracy'] * 100, 2),\n",
    "        'Test Loss': round(r['performance']['test_loss'], 4),\n",
    "        'Parameters (M)': round(r['efficiency']['total_parameters'] / 1e6, 2),\n",
    "        'Model Size (MB)': r['efficiency']['model_size_mb'],\n",
    "        'Training Time (h)': round(hours, 2),\n",
    "        'Inference (ms)': r['efficiency']['inference_time_single_ms'],\n",
    "        'Pretrained': 'No' if name == 'Custom CNN' else 'Yes'\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Highlight best values\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"[Best Performance]\")\n",
    "best_acc_idx = summary_df['Test Accuracy (%)'].idxmax()\n",
    "best_size_idx = summary_df['Model Size (MB)'].idxmin()\n",
    "best_time_idx = summary_df['Training Time (h)'].idxmin()\n",
    "print(f\"  Highest Accuracy:  {summary_df.loc[best_acc_idx, 'Model']} ({summary_df.loc[best_acc_idx, 'Test Accuracy (%)']}%)\")\n",
    "print(f\"  Smallest Model:    {summary_df.loc[best_size_idx, 'Model']} ({summary_df.loc[best_size_idx, 'Model Size (MB)']} MB)\")\n",
    "print(f\"  Fastest Training:  {summary_df.loc[best_time_idx, 'Model']} ({summary_df.loc[best_time_idx, 'Training Time (h)']} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 691
    },
    "id": "6Fefd5NqWGit",
    "outputId": "996ef2a2-ce0a-489a-9adb-896fbded1f46"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: ACCURACY COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ACCURACY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "models = list(results.keys())\n",
    "accuracies = [r['performance']['test_accuracy'] * 100 for r in results.values()]\n",
    "colors = [COLORS[m] for m in models]\n",
    "\n",
    "bars = ax.bar(models, accuracies, color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "            f'{acc:.2f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Test Accuracy (%)')\n",
    "ax.set_title('Model Comparison: Test Set Accuracy')\n",
    "ax.set_ylim(95, 100.5)\n",
    "ax.axhline(y=99, color='gray', linestyle='--', alpha=0.5, label='99% threshold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/comparison_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved: comparison_accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "ndLYqvMsWGiu",
    "outputId": "9bb26655-5599-4430-e3c4-9d2a6e62ab31"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: EFFICIENCY COMPARISON\n",
    "# ============================================================================\n",
    "# Compare model size, parameters, and inference time.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EFFICIENCY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "models = list(results.keys())\n",
    "colors = [COLORS[m] for m in models]\n",
    "\n",
    "# Parameters\n",
    "params = [r['efficiency']['total_parameters'] / 1e6 for r in results.values()]\n",
    "axes[0].bar(models, params, color=colors, edgecolor='black')\n",
    "axes[0].set_ylabel('Parameters (Millions)')\n",
    "axes[0].set_title('Total Parameters')\n",
    "for i, (m, p) in enumerate(zip(models, params)):\n",
    "    axes[0].text(i, p + 0.5, f'{p:.1f}M', ha='center', fontweight='bold')\n",
    "\n",
    "# Model Size\n",
    "sizes = [r['efficiency']['model_size_mb'] for r in results.values()]\n",
    "axes[1].bar(models, sizes, color=colors, edgecolor='black')\n",
    "axes[1].set_ylabel('Size (MB)')\n",
    "axes[1].set_title('Model File Size')\n",
    "for i, (m, s) in enumerate(zip(models, sizes)):\n",
    "    axes[1].text(i, s + 3, f'{s:.1f}', ha='center', fontweight='bold')\n",
    "\n",
    "# Inference Time\n",
    "inf_times = [r['efficiency']['inference_time_single_ms'] for r in results.values()]\n",
    "axes[2].bar(models, inf_times, color=colors, edgecolor='black')\n",
    "axes[2].set_ylabel('Time (ms)')\n",
    "axes[2].set_title('Single Image Inference')\n",
    "for i, (m, t) in enumerate(zip(models, inf_times)):\n",
    "    axes[2].text(i, t + 1, f'{t:.1f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/comparison_efficiency.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved: comparison_efficiency.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "OMvsbIzTWGiu",
    "outputId": "f5176a16-c3fb-4b35-c0a1-fe88e30bbd33"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: PER-CLASS F1 SCORE COMPARISON\n",
    "# ============================================================================\n",
    "# Heatmap showing F1 scores across all classes for each model.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PER-CLASS F1 SCORE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract class names from first model\n",
    "class_names = list(results['Custom CNN']['per_class_metrics'].keys())\n",
    "\n",
    "# Build F1 matrix\n",
    "f1_data = {}\n",
    "for model_name, r in results.items():\n",
    "    f1_data[model_name] = [r['per_class_metrics'][c]['f1_score'] for c in class_names]\n",
    "\n",
    "f1_df = pd.DataFrame(f1_data, index=class_names)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(f1_df, annot=True, fmt='.3f', cmap='RdYlGn',\n",
    "            vmin=0.95, vmax=1.0, ax=ax, cbar_kws={'label': 'F1 Score'})\n",
    "ax.set_title('Per-Class F1 Scores by Model')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Food Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/comparison_f1_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print classes where Custom CNN struggles\n",
    "print(\"\\n[Custom CNN Weakest Classes]\")\n",
    "cnn_f1 = pd.Series(f1_data['Custom CNN'], index=class_names).sort_values()\n",
    "for cls, score in cnn_f1.head(3).items():\n",
    "    print(f\"  {cls}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nPlot saved: comparison_f1_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "C_CBezzBWGiv",
    "outputId": "23c73dc4-cab1-4139-bdb5-7522ee3d2fb8"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: TRAINING TIME VS ACCURACY TRADE-OFF\n",
    "# ============================================================================\n",
    "# Scatter plot showing the relationship between training investment and results.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING TIME VS ACCURACY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for model_name, r in results.items():\n",
    "    hours = r['training']['training_time_seconds'] / 3600\n",
    "    acc = r['performance']['test_accuracy'] * 100\n",
    "    size = r['efficiency']['model_size_mb']\n",
    "\n",
    "    ax.scatter(hours, acc, s=size*3, c=COLORS[model_name],\n",
    "               label=f\"{model_name} ({size:.0f}MB)\", edgecolors='black', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Training Time (hours)')\n",
    "ax.set_ylabel('Test Accuracy (%)')\n",
    "ax.set_title('Training Time vs Accuracy (bubble size = model size)')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(97, 100.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/comparison_tradeoff.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved: comparison_tradeoff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXoOdyHEWGiv",
    "outputId": "81f8cafa-4b2e-4d8e-8077-121a3e78d377"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: STATISTICAL SIGNIFICANCE ANALYSIS\n",
    "# ============================================================================\n",
    "# Evaluate whether performance differences are statistically significant.\n",
    "# Using confidence intervals based on test set size.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STATISTICAL SIGNIFICANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test set size (from classification report support totals)\n",
    "test_size = sum(results['Custom CNN']['per_class_metrics'][c]['support']\n",
    "                for c in results['Custom CNN']['per_class_metrics'])\n",
    "print(f\"Test set size: {test_size:,} samples\")\n",
    "\n",
    "# Calculate 95% confidence intervals using Wilson score\n",
    "from scipy.stats import norm\n",
    "\n",
    "def wilson_ci(p, n, z=1.96):\n",
    "    \"\"\"Wilson score confidence interval for proportion.\"\"\"\n",
    "    denominator = 1 + z**2/n\n",
    "    centre = (p + z**2/(2*n)) / denominator\n",
    "    margin = z * np.sqrt((p*(1-p) + z**2/(4*n))/n) / denominator\n",
    "    return centre - margin, centre + margin\n",
    "\n",
    "print(\"\\n[95% Confidence Intervals]\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "ci_data = []\n",
    "for model_name, r in results.items():\n",
    "    acc = r['performance']['test_accuracy']\n",
    "    lower, upper = wilson_ci(acc, test_size)\n",
    "    ci_data.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': f\"{acc*100:.2f}%\",\n",
    "        '95% CI': f\"[{lower*100:.2f}%, {upper*100:.2f}%]\"\n",
    "    })\n",
    "    print(f\"  {model_name:15s}: {acc*100:.2f}%  CI: [{lower*100:.2f}%, {upper*100:.2f}%]\")\n",
    "\n",
    "# Check for overlapping CIs\n",
    "print(\"\\n[Interpretation]\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "cnn_acc = results['Custom CNN']['performance']['test_accuracy']\n",
    "eff_acc = results['EfficientNetB0']['performance']['test_accuracy']\n",
    "res_acc = results['ResNet-50']['performance']['test_accuracy']\n",
    "\n",
    "cnn_ci = wilson_ci(cnn_acc, test_size)\n",
    "eff_ci = wilson_ci(eff_acc, test_size)\n",
    "res_ci = wilson_ci(res_acc, test_size)\n",
    "\n",
    "# Check overlaps\n",
    "eff_vs_res_overlap = not (eff_ci[1] < res_ci[0] or res_ci[1] < eff_ci[0])\n",
    "cnn_vs_eff_overlap = not (cnn_ci[1] < eff_ci[0] or eff_ci[1] < cnn_ci[0])\n",
    "\n",
    "print(f\"  EfficientNetB0 vs ResNet-50: {'Overlapping CIs (not significant)' if eff_vs_res_overlap else 'Non-overlapping (significant)'}\")\n",
    "print(f\"  Custom CNN vs Transfer Learning: {'Overlapping CIs' if cnn_vs_eff_overlap else 'Non-overlapping (significant)'}\")\n",
    "\n",
    "if eff_vs_res_overlap:\n",
    "    print(\"\\n  -> EfficientNetB0 and ResNet-50 perform comparably.\")\n",
    "    print(\"     The ~0.01% difference is within statistical noise.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "KhOrOjStWGiw",
    "outputId": "1bfd0ccb-4d3e-4e86-90ed-572f651593d8"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 11: MULTI-DIMENSIONAL RADAR CHART\n",
    "# ============================================================================\n",
    "# Visualise trade-offs across multiple metrics simultaneously.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MULTI-DIMENSIONAL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Normalise metrics to 0-1 scale (higher = better for all)\n",
    "metrics = {\n",
    "    'Accuracy': [r['performance']['test_accuracy'] for r in results.values()],\n",
    "    'Speed': [1/r['efficiency']['inference_time_single_ms'] for r in results.values()],\n",
    "    'Compactness': [1/r['efficiency']['model_size_mb'] for r in results.values()],\n",
    "    'Training Efficiency': [1/r['training']['training_time_seconds'] for r in results.values()],\n",
    "    'Parameter Efficiency': [r['performance']['test_accuracy']/(r['efficiency']['total_parameters']/1e6) for r in results.values()]\n",
    "}\n",
    "\n",
    "# Normalise each metric\n",
    "normalised = {}\n",
    "for metric, values in metrics.items():\n",
    "    min_v, max_v = min(values), max(values)\n",
    "    if max_v > min_v:\n",
    "        normalised[metric] = [(v - min_v) / (max_v - min_v) for v in values]\n",
    "    else:\n",
    "        normalised[metric] = [1.0] * len(values)\n",
    "\n",
    "# Create radar chart\n",
    "categories = list(normalised.keys())\n",
    "n_cats = len(categories)\n",
    "angles = [n / float(n_cats) * 2 * np.pi for n in range(n_cats)]\n",
    "angles += angles[:1]  # Close the polygon\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "for i, (model_name, color) in enumerate(COLORS.items()):\n",
    "    values = [normalised[cat][i] for cat in categories]\n",
    "    values += values[:1]  # Close polygon\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=model_name, color=color)\n",
    "    ax.fill(angles, values, alpha=0.15, color=color)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_title('Multi-Dimensional Model Comparison\\n(normalised, higher = better)', pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/comparison_radar.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved: comparison_radar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 943
    },
    "id": "ivRGQAH-oWUt",
    "outputId": "33b2e732-04dd-4a51-f154-b00777dfbf1b"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 12: COMPREHENSIVE GROUPED BAR CHART\n",
    "# ============================================================================\n",
    "# Single chart comparing ALL key metrics across all three models.\n",
    "# Each model has a consistent colour; metrics are grouped as pillars.\n",
    "# Metrics are normalised to percentage scale for visual comparison.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON CHART\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ---- Extract raw metrics ----\n",
    "model_names = list(results.keys())\n",
    "\n",
    "raw_metrics = {\n",
    "    'Test\\nAccuracy (%)': [\n",
    "        r['performance']['test_accuracy'] * 100 for r in results.values()\n",
    "    ],\n",
    "    'Macro\\nF1 Score': [\n",
    "        np.mean([c['f1_score'] for c in r['per_class_metrics'].values()]) * 100\n",
    "        for r in results.values()\n",
    "    ],\n",
    "    'Macro\\nPrecision': [\n",
    "        np.mean([c['precision'] for c in r['per_class_metrics'].values()]) * 100\n",
    "        for r in results.values()\n",
    "    ],\n",
    "    'Macro\\nRecall': [\n",
    "        np.mean([c['recall'] for c in r['per_class_metrics'].values()]) * 100\n",
    "        for r in results.values()\n",
    "    ],\n",
    "    'Parameters\\n(M)': [\n",
    "        r['efficiency']['total_parameters'] / 1e6 for r in results.values()\n",
    "    ],\n",
    "    'Model\\nSize (MB)': [\n",
    "        r['efficiency']['model_size_mb'] for r in results.values()\n",
    "    ],\n",
    "    'Inference\\n(ms)': [\n",
    "        r['efficiency']['inference_time_single_ms'] for r in results.values()\n",
    "    ],\n",
    "    'Training\\nTime (h)': [\n",
    "        r['training']['training_time_seconds'] / 3600 for r in results.values()\n",
    "    ],\n",
    "    'Total\\nEpochs': [\n",
    "        r['training']['total_epochs'] for r in results.values()\n",
    "    ],\n",
    "}\n",
    "\n",
    "metric_names = list(raw_metrics.keys())\n",
    "n_metrics = len(metric_names)\n",
    "n_models = len(model_names)\n",
    "\n",
    "# ---- Normalise to 0-100 per metric (for visual comparison) ----\n",
    "normalised = {}\n",
    "for metric, values in raw_metrics.items():\n",
    "    max_val = max(values) if max(values) > 0 else 1\n",
    "    normalised[metric] = [(v / max_val) * 100 for v in values]\n",
    "\n",
    "# ---- Plot ----\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "\n",
    "bar_width = 0.22\n",
    "x = np.arange(n_metrics)\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    values = [normalised[m][i] for m in metric_names]\n",
    "    raw_vals = [raw_metrics[m][i] for m in metric_names]\n",
    "    offset = (i - (n_models - 1) / 2) * bar_width\n",
    "    bars = ax.bar(\n",
    "        x + offset, values, bar_width,\n",
    "        label=model_name,\n",
    "        color=COLORS[model_name],\n",
    "        edgecolor='black',\n",
    "        linewidth=0.8,\n",
    "        alpha=0.9\n",
    "    )\n",
    "    # Add raw value labels on top of each bar\n",
    "    for bar, raw_val in zip(bars, raw_vals):\n",
    "        height = bar.get_height()\n",
    "        if raw_val >= 90:\n",
    "            label = f'{raw_val:.2f}'\n",
    "        elif raw_val >= 10:\n",
    "            label = f'{raw_val:.1f}'\n",
    "        elif raw_val >= 1:\n",
    "            label = f'{raw_val:.2f}'\n",
    "        else:\n",
    "            label = f'{raw_val:.3f}'\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2, height + 1.5,\n",
    "            label, ha='center', va='bottom',\n",
    "            fontsize=7.5, fontweight='bold', rotation=0\n",
    "        )\n",
    "\n",
    "ax.set_ylabel('Normalised Scale (% of max per metric)', fontsize=12)\n",
    "ax.set_title(\n",
    "    'Comprehensive Model Comparison: All Metrics',\n",
    "    fontsize=15, fontweight='bold', pad=15\n",
    ")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metric_names, fontsize=10, ha='center')\n",
    "ax.set_ylim(0, 120)\n",
    "ax.legend(fontsize=11, loc='upper right', framealpha=0.9)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add a subtle separator between performance and efficiency metrics\n",
    "ax.axvline(x=3.5, color='gray', linestyle=':', alpha=0.4, linewidth=1)\n",
    "ax.text(1.5, 115, 'PERFORMANCE', ha='center', fontsize=9,\n",
    "        fontstyle='italic', color='gray', alpha=0.7)\n",
    "ax.text(6.5, 115, 'EFFICIENCY & TRAINING', ha='center', fontsize=9,\n",
    "        fontstyle='italic', color='gray', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/comparison_comprehensive.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved: comparison_comprehensive.png\")\n",
    "print(\"\\nNote: Bar heights are normalised (tallest bar = 100% per metric).\")\n",
    "print(\"Raw values are displayed above each bar for exact comparison.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "id": "uoHaxvoroWUu",
    "outputId": "ad44cbe3-f9b1-47ea-c7a5-86ce3ba6fff8"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 13: MODEL PROFILE COMPARISON\n",
    "# ============================================================================\n",
    "# Each model displayed as its own group with all metrics side by side,\n",
    "# using the model's signature colour. Allows quick visual profiling of\n",
    "# each architecture's strengths and weaknesses in a single glance.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL PROFILE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model_names = list(results.keys())\n",
    "\n",
    "# ---- Define metrics (short labels for this layout) ----\n",
    "metric_defs = {\n",
    "    'Accuracy':   lambda r: r['performance']['test_accuracy'] * 100,\n",
    "    'F1 Score':   lambda r: np.mean([c['f1_score'] for c in r['per_class_metrics'].values()]) * 100,\n",
    "    'Precision':  lambda r: np.mean([c['precision'] for c in r['per_class_metrics'].values()]) * 100,\n",
    "    'Recall':     lambda r: np.mean([c['recall'] for c in r['per_class_metrics'].values()]) * 100,\n",
    "    'Params (M)': lambda r: r['efficiency']['total_parameters'] / 1e6,\n",
    "    'Size (MB)':  lambda r: r['efficiency']['model_size_mb'],\n",
    "    'Infer (ms)': lambda r: r['efficiency']['inference_time_single_ms'],\n",
    "    'Train (h)':  lambda r: r['training']['training_time_seconds'] / 3600,\n",
    "    'Epochs':     lambda r: r['training']['total_epochs'],\n",
    "}\n",
    "\n",
    "metric_labels = list(metric_defs.keys())\n",
    "n_metrics = len(metric_labels)\n",
    "\n",
    "# ---- Extract raw values per model ----\n",
    "raw_per_model = {}\n",
    "for name, r in results.items():\n",
    "    raw_per_model[name] = [fn(r) for fn in metric_defs.values()]\n",
    "\n",
    "# ---- Normalise each metric across all models (0-100, max = 100) ----\n",
    "all_values = {m: [] for m in metric_labels}\n",
    "for name in model_names:\n",
    "    for j, m in enumerate(metric_labels):\n",
    "        all_values[m].append(raw_per_model[name][j])\n",
    "\n",
    "norm_per_model = {}\n",
    "for name in model_names:\n",
    "    norm_per_model[name] = []\n",
    "    for j, m in enumerate(metric_labels):\n",
    "        max_val = max(all_values[m]) if max(all_values[m]) > 0 else 1\n",
    "        norm_per_model[name].append(raw_per_model[name][j] / max_val * 100)\n",
    "\n",
    "# ---- Plot: 3 model groups, each with n_metrics bars ----\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "\n",
    "bar_width = 0.7\n",
    "group_gap = 2.5  # space between model groups\n",
    "n_models = len(model_names)\n",
    "\n",
    "positions = []  # track all bar positions for xtick placement\n",
    "group_centres = []\n",
    "\n",
    "x_cursor = 0\n",
    "for i, model_name in enumerate(model_names):\n",
    "    color = COLORS[model_name]\n",
    "    model_positions = []\n",
    "\n",
    "    for j in range(n_metrics):\n",
    "        pos = x_cursor + j\n",
    "        model_positions.append(pos)\n",
    "        bar = ax.bar(\n",
    "            pos, norm_per_model[model_name][j], bar_width,\n",
    "            color=color, edgecolor='black', linewidth=0.6, alpha=0.88\n",
    "        )\n",
    "        # Raw value label\n",
    "        raw_val = raw_per_model[model_name][j]\n",
    "        if raw_val >= 90:\n",
    "            label = f'{raw_val:.2f}'\n",
    "        elif raw_val >= 10:\n",
    "            label = f'{raw_val:.1f}'\n",
    "        elif raw_val >= 1:\n",
    "            label = f'{raw_val:.2f}'\n",
    "        else:\n",
    "            label = f'{raw_val:.3f}'\n",
    "        ax.text(\n",
    "            pos, norm_per_model[model_name][j] + 1.5, label,\n",
    "            ha='center', va='bottom', fontsize=7.5, fontweight='bold'\n",
    "        )\n",
    "\n",
    "    positions.extend(model_positions)\n",
    "    group_centres.append(np.mean(model_positions))\n",
    "    x_cursor += n_metrics + group_gap\n",
    "\n",
    "# X-axis: metric labels repeated under each group\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(metric_labels * n_models, fontsize=8.5, rotation=45, ha='right')\n",
    "\n",
    "# Model name labels above each group\n",
    "for centre, name in zip(group_centres, model_names):\n",
    "    ax.text(\n",
    "        centre, 113, name, ha='center', va='bottom',\n",
    "        fontsize=13, fontweight='bold', color=COLORS[name],\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor=COLORS[name],\n",
    "                  alpha=0.15, edgecolor=COLORS[name], linewidth=1.5)\n",
    "    )\n",
    "\n",
    "# Vertical separators between groups\n",
    "for i in range(1, n_models):\n",
    "    sep_x = group_centres[i-1] + (group_centres[i] - group_centres[i-1]) / 2\n",
    "    ax.axvline(x=sep_x, color='gray', linestyle='--', alpha=0.3, linewidth=1)\n",
    "\n",
    "ax.set_ylabel('Normalised Scale (% of max per metric)', fontsize=12)\n",
    "ax.set_title(\n",
    "    'Model Profiles: Per-Architecture Metric Breakdown',\n",
    "    fontsize=15, fontweight='bold', pad=20\n",
    ")\n",
    "ax.set_ylim(0, 125)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/comparison_model_profiles.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved: comparison_model_profiles.png\")\n",
    "print(\"\\nEach group shows one model\\'s full metric profile in its signature colour.\")\n",
    "print(\"Raw values displayed above bars; heights normalised across models per metric.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LI9jIlT3WGiw",
    "outputId": "d1693c79-32cf-40e1-92df-a98c4745f1d8"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 12: COMPREHENSIVE RESULTS TABLE\n",
    "# ============================================================================\n",
    "# Full breakdown suitable for dissertation appendix.\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPREHENSIVE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "detailed_data = []\n",
    "for name, r in results.items():\n",
    "    # Calculate macro-averaged metrics from per-class data\n",
    "    classes = r['per_class_metrics']\n",
    "    macro_precision = np.mean([c['precision'] for c in classes.values()])\n",
    "    macro_recall = np.mean([c['recall'] for c in classes.values()])\n",
    "    macro_f1 = np.mean([c['f1_score'] for c in classes.values()])\n",
    "\n",
    "    detailed_data.append({\n",
    "        'Model': name,\n",
    "        'Architecture': r['architecture'].get('type', 'Transfer Learning'),\n",
    "        'Test Accuracy': f\"{r['performance']['test_accuracy']*100:.2f}%\",\n",
    "        'Macro Precision': f\"{macro_precision:.4f}\",\n",
    "        'Macro Recall': f\"{macro_recall:.4f}\",\n",
    "        'Macro F1': f\"{macro_f1:.4f}\",\n",
    "        'Parameters': f\"{r['efficiency']['total_parameters']:,}\",\n",
    "        'Size (MB)': r['efficiency']['model_size_mb'],\n",
    "        'Training (h)': round(r['training']['training_time_seconds']/3600, 2),\n",
    "        'Epochs': r['training']['total_epochs'],\n",
    "        'Best Epoch': r['training']['best_epoch']\n",
    "    })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_data)\n",
    "print(detailed_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LByc2q_oWUu",
    "outputId": "2f2c2216-c1ec-4d7f-d423-cfe91f46394d"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 14: SAVE COMPARISON OUTPUTS\n",
    "# ============================================================================\n",
    "# Export comparison results and copy plots to Drive.\n",
    "# ============================================================================\n",
    "\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SAVING OUTPUTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "COMPARISON_DIR = \"/content/comparison_outputs\"\n",
    "os.makedirs(COMPARISON_DIR, exist_ok=True)\n",
    "\n",
    "# Save summary CSV\n",
    "summary_df.to_csv(f\"{COMPARISON_DIR}/model_comparison_summary.csv\", index=False)\n",
    "print(f\"Saved: model_comparison_summary.csv\")\n",
    "\n",
    "# Save detailed CSV\n",
    "detailed_df.to_csv(f\"{COMPARISON_DIR}/model_comparison_detailed.csv\", index=False)\n",
    "print(f\"Saved: model_comparison_detailed.csv\")\n",
    "\n",
    "# Save F1 heatmap data\n",
    "f1_df.to_csv(f\"{COMPARISON_DIR}/per_class_f1_scores.csv\")\n",
    "print(f\"Saved: per_class_f1_scores.csv\")\n",
    "\n",
    "# Copy plots\n",
    "plots = [\n",
    "    'comparison_accuracy.png',\n",
    "    'comparison_efficiency.png',\n",
    "    'comparison_f1_heatmap.png',\n",
    "    'comparison_tradeoff.png',\n",
    "    'comparison_radar.png',\n",
    "    'comparison_comprehensive.png',\n",
    "    'comparison_model_profiles.png'\n",
    "]\n",
    "\n",
    "for plot in plots:\n",
    "    src = f'/content/{plot}'\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, f\"{COMPARISON_DIR}/{plot}\")\n",
    "        print(f\"Saved: {plot}\")\n",
    "\n",
    "print(f\"\\nAll outputs saved to: {COMPARISON_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QCCQyIF5oWUv",
    "outputId": "7658bc4b-0065-44b7-ed32-735d504a73a0"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 15: FINAL SUMMARY AND CONCLUSIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL COMPARISON - FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract key metrics\n",
    "cnn = results['Custom CNN']\n",
    "eff = results['EfficientNetB0']\n",
    "res = results['ResNet-50']\n",
    "\n",
    "print(f\"\"\"\n",
    "EXPERIMENT CONFIGURATION\n",
    "----------------------------------------------------------------------\n",
    "Dataset:        SnapShelf 14-class food classification\n",
    "Train/Val/Test: 84,582 / 18,119 / 18,141 images\n",
    "Image Size:     224x224 RGB\n",
    "Class Imbalance: 113:1 (handled via class weights)\n",
    "Augmentation:   Rotation, shifts, shear, zoom, horizontal flip\n",
    "\n",
    "PERFORMANCE RESULTS\n",
    "----------------------------------------------------------------------\n",
    "                    Custom CNN    EfficientNetB0    ResNet-50\n",
    "Test Accuracy       {cnn['performance']['test_accuracy']*100:.2f}%         {eff['performance']['test_accuracy']*100:.2f}%           {res['performance']['test_accuracy']*100:.2f}%\n",
    "Test Loss           {cnn['performance']['test_loss']:.4f}          {eff['performance']['test_loss']:.4f}            {res['performance']['test_loss']:.4f}\n",
    "Parameters          {cnn['efficiency']['total_parameters']/1e6:.2f}M          {eff['efficiency']['total_parameters']/1e6:.2f}M            {res['efficiency']['total_parameters']/1e6:.2f}M\n",
    "Model Size          {cnn['efficiency']['model_size_mb']:.1f}MB         {eff['efficiency']['model_size_mb']:.1f}MB           {res['efficiency']['model_size_mb']:.1f}MB\n",
    "Training Time       {cnn['training']['training_time_seconds']/3600:.1f}h*          {eff['training']['training_time_seconds']/3600:.1f}h             {res['training']['training_time_seconds']/3600:.1f}h\n",
    "\n",
    "* Custom CNN training time estimated via per-epoch extrapolation due to\n",
    "  a runtime interruption at epoch 66 (see Cell 4 correction note).\n",
    "\n",
    "KEY FINDINGS\n",
    "----------------------------------------------------------------------\n",
    "1. Transfer learning models (EfficientNetB0, ResNet-50) significantly\n",
    "   outperform the Custom CNN baseline by ~1.8 percentage points.\n",
    "\n",
    "2. EfficientNetB0 achieves comparable accuracy to ResNet-50 while being\n",
    "   significantly smaller and faster to train.\n",
    "\n",
    "3. The Custom CNN trained from scratch required {cnn['training']['training_time_seconds']/3600:.1f}h for 81\n",
    "   epochs, confirming the computational cost of learning features from\n",
    "   random initialisation versus leveraging pretrained ImageNet weights.\n",
    "\n",
    "4. All models handle the severe class imbalance effectively,\n",
    "   maintaining high F1 scores across minority classes.\n",
    "\n",
    "RECOMMENDATION\n",
    "----------------------------------------------------------------------\n",
    "EfficientNetB0 is the recommended model for deployment due to its\n",
    "optimal balance of accuracy ({eff['performance']['test_accuracy']*100:.2f}%), efficiency ({eff['efficiency']['model_size_mb']:.0f}MB),\n",
    "and training cost ({eff['training']['training_time_seconds']/3600:.1f} hours).\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPARISON ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ]
}